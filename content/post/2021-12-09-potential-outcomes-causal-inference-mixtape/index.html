---
title: Potential Outcomes Model (or why correlation is not causality)
author: Francisco Yirá
date: '2021-12-09'
slug: potential-outcomes-causal-inference-mixtape
cover: "images/homer_potential_outcomes.jpg"
useRelativeCover: true
isMath: "true"
categories:
  - books
  - causal-inference
  - data-science
tags:
  - causal-inference-the-mixtape
  - summaries
  - potential-outcomes
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<p>This article, the second one of <a href="https://www.franciscoyira.com/tags/causal-inference-the-mixtape/">the series</a> about the book <a href="https://mixtape.scunning.com/">Causal Inference: The Mixtape</a>, is all about the <strong>Potential Outcomes notation</strong> and how it enables us to tackle causality questions and understand key concepts in this field<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>.</p>
<p>The central idea of this notation is the <strong>comparison between 2 states of the world</strong>:</p>
<ul>
<li><p><strong>The actual state</strong>: the outcomes observed in the data given the real value taken by some treatment variable. For example, the quarterly sales of a company given that they did some marketing campaign.</p></li>
<li><p><strong>The counterfactual state:</strong> what would have happened if the treatment variable had taken another value. For example, the quarterly sales of the company if the marketing campaign had not been carried out.</p></li>
</ul>
<p>The <strong>causal effect</strong> of an intervention (in this case, the marketing campaign) is the difference in the outcome variable between these two states. Thus, to calculate it, it would suffice to do a subtraction between them… but we can’t actually do that because <strong>the counterfactual value is hypothetical and unknown</strong>. Counterfactuals don’t really exist because as soon as one of the possible scenarios materializes, then all the other potential outcomes disappear.</p>
<p>In the company example, when the marketing campaign is carried out, it is no longer possible to know how much would have been the sales if the campaign had been ditched. We can have hypotheses or guesses, but we will never know for sure the counterfactual value for this individual company.</p>
<p>The good news is that by having data for many companies (and when some special conditions are met) we can still get a reasonable <strong>estimate</strong> for the <strong>average effect</strong> of a generic marketing campaign over that <em>group</em> of companies.</p>
<p>Now let’s translate these concepts into the potential outcomes notation.</p>
<div id="potential-outcomes-notation" class="section level2">
<h2>Potential outcomes notation</h2>
<p>First, we define the variable <span class="math inline">\(D_i\)</span>, which represents if the unit <span class="math inline">\(i\)</span> receives the treatment or not<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>. In the previous example, this variable will take the value 1 if the company <span class="math inline">\(i\)</span> executes the marketing campaign and 0 if not.</p>
<p>Then we define the variable <span class="math inline">\(Y_i\)</span>, which represents <strong>the outcome of interest</strong> for the unit <span class="math inline">\(i\)</span> (let’s say, the quarterly sales of the company <span class="math inline">\(i\)</span>).</p>
<p>This outcome variable can also have a superindex, which usually takes values 0 or 1 and indicates to which value of <span class="math inline">\(D\)</span> is the outcome associated. In our example, the superindex tells us if the outcome (sales) corresponds to a world where the company <span class="math inline">\(i\)</span> implemented the marketing campaign (<span class="math inline">\(Y_i^1\)</span>) or to one where it didn’t (<span class="math inline">\(Y_i^0\)</span>).</p>
<p>It’s important to note that the superindex by itself <strong><em>does not</em></strong> tell us if the outcome is actual or counterfactual. To know if an outcome is counterfactual or not, we need an additional piece of notation:</p>
<p><span class="math display">\[
Y_i^1|D_i=0
\]</span></p>
<p>Now this expression is interpreted as “the sales of the company <span class="math inline">\(i\)</span> in the world where the marketing campaign is carried out, <em>conditional on the fact that it did not actually implement the campaign</em>”.</p>
<p>In other words, the superindex denotes a hypothetical scenario for <span class="math inline">\(Y_i\)</span>, and what comes after <span class="math inline">\(|\)</span> indicates what really happened with the unit <span class="math inline">\(i\)</span>. If these two values match, then the whole expression is a real outcome, and if they’re different, it’s a counterfactual outcome (and therefore, it’s unknown).</p>
<p><img src="images/counterfactuals.jpg" width="750" /></p>
<p>The previous idea can be summarized through the so-called <strong><em>switching equation</em></strong>:</p>
<p><span class="math display">\[
Y_i = D_iY_i^1+(1-D_i)Y_i^0
\]</span></p>
<p>Which can be better understood with this meme:</p>
<div class="figure">
<img src="images/meme_potential_outcomes.jpg" width="400" alt="" />
<p class="caption"><em>Meme <del>stolen</del> borrowed from the book <a href="https://matheusfacure.github.io/python-causality-handbook/01-Introduction-To-Causality.html">Causal Inference for the Brave and True</a></em></p>
</div>
<p>The key idea here is that, in the real world, we only know the actual outcome (<span class="math inline">\(Y_i\)</span>), which is the materialization of one of the potential outcomes (<span class="math inline">\(Y_i^1, Y_i^0\)</span>) based on the value taken by <span class="math inline">\(D_i\)</span>: if <span class="math inline">\(D_i=1\)</span>, then <span class="math inline">\(1-D_i=0\)</span> and the equation collapses to <span class="math inline">\(Y_i=Y_i^1\)</span> (and vice versa when <span class="math inline">\(D_i=0\)</span>).</p>
<p><img src="images/switching_equation_explained.png" width="500" />
Thus, the non-materialized potential outcome is relegated to be a <em>counterfactual</em> (i.e. a fictional concept in our imagination).</p>
<p>Using all the notation we’ve already defined, we can also define the <strong>causal effect</strong> of the marketing campaign for the company <span class="math inline">\(i\)</span> (that is, the difference between the sales if the campaign had been carried out and the sales if it hadn’t).</p>
<p><span class="math display">\[
\delta_i=Y_i^1-Y_i^0
\]</span>
As we only see one of the two potential outcomes for the unit <span class="math inline">\(i\)</span>, the value <span class="math inline">\(\delta_i\)</span> is unobservable. Note also that the subindex <span class="math inline">\(i\)</span> tells us that this causal effect can be different for other units (in general, <span class="math inline">\(\delta_i\ne\delta_j\)</span>).</p>
</div>
<div id="average-effects-ate-y-att" class="section level2">
<h2>Average effects: ATE y ATT</h2>
<p>Despite not being able to know the treatment effects for each unit <span class="math inline">\(i\)</span>, under some circumstances we can estimate average effects for a group of units.</p>
<p>There are different names for these average effects, depending on which group of units we are referring to. The most relevant ones are:</p>
<ul>
<li><u><strong>A</strong></u><strong>verage <u>T</u>reatment <u>E</u>ffect (ATE):</strong> It’s the average of the effects on all the units in our analysis.</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
ATE &amp;= E[\delta_i]\\
&amp;= E[Y_i^1 - Y_i^0]\\
&amp;= E[Y_i^1]-E[Y_i^0]
\end{aligned}
\]</span></p>
<ul>
<li><u><strong>A</strong></u><strong>verage <u>T</u>reatment Effect on the <u>T</u>reated (ATT):</strong> Similar to the ATE, but only considering the units that actually received the treatment (<span class="math inline">\(|D_i=1\)</span>)<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>.</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
ATT &amp;= E[\delta_i|D_i=1]\\
&amp;= E[Y_i^1 - Y_i^0|D_i=1]\\
&amp;= E[Y_i^1|D_i=1]-E[Y_i^0|D_i=1]
\end{aligned}
\]</span>
We must remember that even though some units did receive the treatment, they still have (conceptually) a potential outcome without treatment (<span class="math inline">\(Y_i^0\)</span>). Besides, since the effects <span class="math inline">\(\delta_i\)</span> can be different between units (and usually they are), more often than not the ATE and ATT will have different values too.</p>
<p>Something problematic here is that the ATE and ATT are still functions of counterfactual terms, and therefore unobservable and impossible to calculate. But we previously had said that, under some circumstances, we could estimate them. Which are these circumstances?</p>
<p>To explain it, we must introduce a new expression that <em>can</em> be calculated: the <strong>simple difference in outcomes</strong>.</p>
</div>
<div id="simple-difference-in-outcomes-sdo" class="section level2">
<h2>Simple difference in outcomes (SDO)</h2>
<p>Despite the relevance of potential outcomes, the only values we can truly observe in the real world are:</p>
<ul>
<li><p>The actual outcomes: <span class="math inline">\(Y_i\)</span></p></li>
<li><p>The treatment values for the units: <span class="math inline">\(D_i\)</span></p></li>
</ul>
<p>In the context of the previous example, this would mean to observe:</p>
<ul>
<li><p>The sales for each company</p></li>
<li><p>Whether they did a marketing campaign or not (in the period of interest)</p></li>
</ul>
<p>A statistic that can be easily obtained using this data is the difference in average sales between the companies that carried out a marketing campaign and those that did not. This statistic is called the <strong>Simple Difference in Outcomes</strong>, or <strong>SDO</strong>, and can be expressed as follows using the potential outcomes notation:</p>
<p><span class="math display">\[
E[Y^1|D=1] - E[Y^0|D=0]
\]</span></p>
<p>And it can be calculated by using the following formula (where <span class="math inline">\(N_T\)</span> is the number companies with <span class="math inline">\(D_i=1\)</span> and <span class="math inline">\(N_C\)</span> is the number of companies with <span class="math inline">\(D_i=0\)</span>).</p>
<p><span class="math display">\[
\frac{1}{N_T} \sum_{i=1}^n(yi|d_i=1)-\frac{1}{N_C}\sum_{i=1}^{n}(y_i|d_i=0)
\]</span></p>
<p>We can see that this expression <strong>only contains actual outcomes</strong> (observables). Therefore, <strong>it can be calculated</strong>.</p>
<p>However, we intuitively know that attributing causal meaning to this metric is wrong. For instance, it’s likely that companies with a big enough budget to implement a marketing campaign are larger companies, and therefore, they would have had bigger sales even if they didn’t have implemented the campaign.</p>
<p>This intuition is reflected in the <strong>simple difference in outcomes <em>decomposition</em></strong>:
<img src="images/sdo.png" /></p>
<p>What this decomposition tells us is that the SDO is composed of the sum of three expressions:</p>
<ul>
<li><p><a href="https://www.youtube.com/watch?v=Iz-8CSa9xj8">Our precious</a>, the <strong>Average Treatment Effect</strong>.</p></li>
<li><p>Two nasty biases: the <strong>selection bias</strong> (the difference in average sales between groups of companies if none of them would have implemented the marketing campaign) and the <strong>heterogeneus treatment effect bias</strong> (the difference in average <span class="math inline">\(\delta_i\)</span> between groups of companies).</p></li>
</ul>
<p>This decomposition <a href="https://mixtape.scunning.com/potential-outcomes.html#simple-difference-in-means-decomposition">is demonstrated in the book</a>, and it is the “technical” explanation of why the SDO usually doesn’t have a proper causal meaning: selection bias and heterogenous effect bias lead to the SDO being different from the ATE.</p>
<p>The decomposition gives us good and bad news. The good news is that now we have an easy to calculate statistic (the SDO) which <em>technically</em> contains the ATE. The bad news is that in order to “extract” the ATE from the SDO, we need information that we don’t have (since the expressions for the biases contain counterfactual outcomes).</p>
<p>Given this, the light of hope that causal inference offers us is to develop strategies so that, in the data collected, the biases are negligible, and thus making it possible to use the SDO as an estimator of the ATE.</p>
<p>In the own words of <a href="https://www.scunning.com/">Scott Cunningham</a> (author of the book):</p>
<blockquote>
<p>“One could argue that the entire enterprise of causal inference is about developing a reasonable strategy for negating the role that selection bias is playing in estimated causal effects.”</p>
</blockquote>
</div>
<div id="the-independence-assumption-and-the-effectiveness-of-randomization" class="section level2">
<h2>The independence assumption (and the effectiveness of randomization)</h2>
<p>OK, so we want to retrieve unbiased estimates for the average effects, such as the ATE, and we know that most of the time, the SDO isn’t a good estimator for those due to the biases we’ve just talked about. But what is the reason why these biases do appear in the SDO?</p>
<p><strong>Biases</strong> (of selection and heterogeneous effect) <strong>appear when the treatment assignment (</strong><span class="math inline">\(D_i\)</span><strong>) is not independent of the potential outcomes</strong>.</p>
<p>For example, when we say something like “<em>companies with a big enough budget to implement a marketing campaign are larger companies, and therefore, they would have had bigger sales even if they didn’t have implemented the campaign</em>”, what we are really saying, in the language of potential outcomes, is that <span class="math inline">\(D\)</span> depends on <span class="math inline">\(Y^0\)</span>: companies with higher values for <span class="math inline">\(Y^0\)</span> are more likely to have a value of <span class="math inline">\(D\)</span> equal to 1.</p>
<p>From the above, it follows that <strong>when <em>there is</em> independence between treatment assignment and potential outcomes (</strong><span class="math inline">\((Y^1,Y^0)\mathrel{\unicode{x2AEB}}D\)</span><strong>), then the SDO is, in fact, a good estimator for the ATE!</strong> (it’s unbiased)<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>.</p>
<p><img src="https://media2.giphy.com/media/G96zgIcQn1L2xpmdxi/giphy.gif" /></p>
<p>The bad news is that this rarely happens in real life.</p>
<p><img src="https://media2.giphy.com/media/nrg0TI3u0BFw5NBDsQ/giphy.gif" /></p>
<p>As a general rule, whenever the variable <span class="math inline">\(D\)</span> is being freely chosen by human beings, there will be dependence between <span class="math inline">\(D\)</span> and the potential outcomes 😵.</p>
<p>Although we are not <a href="https://en.wikipedia.org/wiki/Homo_economicus"><em>homo economicus</em></a> who make their decisions with perfect information (we don’t know the exact value of the potential outcomes), we do collect information about the available options and their expected outcomes, and we make decisions that we believe will benefit us based on that limited information. This is enough so that such decisions (that is, the <span class="math inline">\(D\)</span> values) are not independent of the potential outcomes.</p>
<p>In the words of Scott Cunningham: “<em>Rational choice is always pushing against the independence assumption</em>”.</p>
<p>One of the exceptions to this is <strong>randomization</strong>, precisely because there is no free choice by agents on it. Since we assign values of <span class="math inline">\(D\)</span> randomly to each unit, we impose independence between those values and the potential outcomes. Thus, <strong>the SDO in randomized trials is usually enough to estimate unbiased causal effects</strong><a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>.</p>
<p><em>Your feedback is welcome! You can send me comments about this article to my <a href="mailto:francisco.yira@outlook.com">email</a>.</em></p>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>The potential outcomes notation was first introduced by <a href="https://www.jstor.org/stable/2245382">Splawa-Neymanen in 1923</a>, and then was popularized <a href="(https://www.fsb.muohio.edu/lij14/420_paper_Rubin74.pdf)">by Rubin in 1974</a>.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>There are cases where the treatment is not binary, but they will be left out of this article in order to keep the explanations simple.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>There is also the ATU (Average Treatment Effect on the Untreated), which is analogous to the ATT but considering only the units which did <em>not</em> receive the treatment. It’s less relevant than the ATE and the ATT, and that’s why I only mention it in a footnote.<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>You can see a demonstration of this in <a href="https://mixtape.scunning.com/potential-outcomes.html#independence-assumption">this section</a> of the book.<a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>I’m saying “usually enough” and not “enough” because despite being randomized, trials still can have biased results due to other problems, such as <a href="https://en.wikipedia.org/wiki/Spillover_(experiment)">spillovers</a>. This can be a topic for another blog post in the future.<a href="#fnref5" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
