---
title: 'Randomization Inference: una mejor forma de calcular p-values en experimentos'
author: Francisco Yirá
date: '2022-01-21'
slug: randomization-inference-causal-mixtape
categories:
  - inferencia-causal
  - libros
  - data-science
  - R
  - tutorial
tags:
  - causal-inference-the-mixtape
  - resumenes
  - p-values
---

Bienvenidos a un nuevo artículo de la serie dedicada al libro Causal Inference: The Mixtape. En el artículo anterior vimos una introducción a la notación de Potential Outcomes y lo importante que es esta para expresar conceptos de causalidad, tales como la posibilidad de usar la diferencia de medias en experimentos aleatorizados como estimador insesgado de efectos causales.

Sin embargo, un par de conceptos que estuvieron totalmente ausentes en ese artículo fueron los de test de hipótesis y varianza. Hablamos de que la diferencia simple de medias (SDO por sus siglas en inglés) tenía la misma *esperanza* que el efecto causal promedio (ATE) cuando la asignación del tratamiento (D) era independiente de los outcomes potenciales ($Y_i^1, Y_i^0$).

Pero en el mundo real no observamos la esperanza sino que realizaciones particulares: dos monedas tienen la misma esperanza de arrojar cara o sello al ser lanzadas, pero si lanzamos cada una 5 veces, es muy probable que el número de caras y sellos difiera entre ellas, simplemente debido a la fluctuación aleatoria o varianza propia de este proceso generador de datos.

Dada esa variabilidad en la diferencia de medias, ¿qué tan grande debe ser este valor observado para que estemos seguros de que existe una diferencia *real* entre el grupo tratado y el grupo de control? (es decir, una diferencia en las esperanzas).

Esta pregunta usualmente se responde realizando un test de medias/regresión lineal/ANOVA. Estos métodos son ampliamente enseñados en los cursos universitarios de estadística y econometría, y existe sobre mucho material disponible en internet para aprenderlos, así que este post no se centra en ellos.

De lo que hablaremos hoy será de una metodología alternativa a los tests de hipótesis tradicionales para experimentos aleatorizados. Esta metodología se llama **randomization inference**, y también responde la pregunta de *qué tan distintos deben ser los valores de tratados y controles*, pero de una forma distinta.

## ¿Por qué usar randomization inference en vez de tests de hipótesis tradicionales?

Una pregunta que quizás te estes haciendo en este momento es porque valdría la pena invertir tiempo en aprender y aplicar randomizacion inference siendo que ya contamos con tests de hipótesis tradicionales que son ampliamente usados y conocidos. Yo me estaría preguntando lo mismo si estuviera en tu lugar.

Las razones para aplicar randomizacion inference en nuestros tests de hipótesis pueden resumirse en las siguientes:

1.  Al hacer inferencia causal con datos experimentales, la principal fuente de incertidumbre no es el muestreo desde una población mas grande sino que la asignación aleatoria del tratamiento combinada con la imposibilidad de conocer los contrafactuales. Los metodos tradicionales de test de hipótesis no toman esto en consideración, sino que se enfocan en la incertidumbre de muestreo. **Esto es particularmente problemático si trabajamos con grandes datasets administrativos que literalmente representan "toda la data"** (a.k.a. bIg dAtA) tales como A/B testings, y puede traducirse en que subestimemos considerablemente la incertidumbre en nuestros resultados. Randomization inference aborda estos problemas al tomar en cuenta la incertidumbre proveniente de la asignación del tratamiento, por lo que resulta un procedimiento mas apropiado en estos casos.

2.  También existen ventajas al estar en el extremo opuesto: datos pequeños y/o muy pocas unidades tratadas. En esto casos no resulta muy creíble apelar a las propiedades de "muestras grandes" en las que se basan los tests convencionales. En particular, podemos sufrir de una alta vulnerabilidad a o utileros y observaciones de alto leverage, lo cual se traduce en riesgo de over-rejection de la hipótesis nula. Randomization inference nos ayuda en tal situación al ser una metodología más robusta a outliers y observaciones de alto leverage.

3.  Finalmente, aun si no existe ningún problema particular con los tests tradicionales, randomization inference nos entrega mucha mas libertad respecto de los estimadores o estadísticos a usar. Mientras que al hacer un test de medias habitual estamos restringidos a aquellos estimadores para los cuales se ha podido derivar la varianza, randomization inference nos abre las puertas para usar cualquier estadístico escalar que pueda obtenerse a partir de un dataset. Algunos ejemplos útiles son los estadísticos en base a quintiles (por ejemplo, la mediana), en base a rankings, o el estadístico KS (Kolmogorov-Smirnov) que mide diferencias en las funciones de distribución acumuladas.

Y como bonus, hacer randomization inference es cool. En el mundo de la inferencia causal existe una preferencia estética por las metodologías de "placebo" que simulan tratamientos falsos en los datos reales y chequear que *no* encontremos un efecto relevante de este tratamiento falso, y asi estar mas seguros de que nuestras conclusiones sobre el tratamiento verdadero son validas[^1]. Más abajo veremos que randomization inference consiste en algo muy similar a esto.

[^1]: Algunas de las metodologías de inferencia causal que se apalancan mucho en tests de placebo son regresión discontinua y diferencias en diferencias. En artículos posteriores entraré en mas detalle al respecto.

\[mencionar que no dependemos de la distribución gaussiana y que es una metodología no parametrica, o quizás mas abajo\]

## En qué consiste randomization inference, y cómo aplicarlo en R

Primero que todo, no debemos perder de vista nuestro objetivo y el contexto en el cual aplicamos este procedimiento: estamos analizando datos provenientes de un experimento aleatorizado. Tenemos un conjunto de observaciones que fueron asignadas aleatoriamente a un grupo de tratamiento o a uno de control, también tenemos una variable de resultados (Y) y queremos medir el efecto promedio del tratamiento sobre dicha variable.

Un problema aquí es que, como dijimos en la introducción, casi siempre existirán diferencias entre el grupo tratado y el grupo de control, simplemente por fluctuación aleatoria (la variabilidad natural del proceso generador de datos).

Soy del tipo de personas que aprenden mucho mejor conceptos estadísticos con ejemplos concretos y fragmentos de código que con notación matemática, así que mi explicación de la metodología será un tutorial paso a paso de como aplicarla en R de forma manual.

Primero, cargamos los paquetes y los datos que usaremos.

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(magrittr)
library(causaldata)
```

```{r}
ri <- causaldata::ri %>% 
  mutate(id_unit = row_number())

ri
```

Como puede verse, este

```{r}
perms <- t(combn(ri$id_unit, 4)) %>% asplit(1) 

perms_df <- 
  tibble(treated_units = perms) %>% 
  transmute(id_perm = row_number(),
            treated_units = map(treated_units, unlist))

perms_df
```

```{r}
combo_df <- 
  crossing(perms_df, ri) %>% 
  mutate(d = map2_dbl(id_unit, treated_units, ~.x %in% .y))

combo_df
```

```{r}
# Obtains the mean outcome for the treated for each permutation of D
perms_stats <- 
  combo_df %>%
  group_by(id_perm) %>%
  # filter(d == 1) %>% 
  summarise(te1 = mean(y[d == 1]),
            te0 = mean(y[d == 0]),
            sdo = te1 - te0)

perms_stats
```

```{r}
perms_ranked <- perms_stats %>%
  select(id_perm, sdo) %>% 
  arrange(desc(abs(sdo))) %>% 
  mutate(rank = row_number(desc(abs(sdo)))) %>% 
  group_by(abs(sdo)) %>% 
  mutate(new_rank = max(rank))

perms_ranked
```

```{r}
n <- nrow(perms_ranked)

p_value <- 
  perms_ranked %>% 
  # The first permutation is the one with the true D vector
  filter(id_perm == 1) %>%
  # We get the proportion of permutations above our "true" permutation. That will be our p-value
  pull(new_rank)/n

p_value
```

Por supuesto, no podriamos usar codigo como este si tuvieramos una cantidad mucho mayor de observaciones.

## Usando el paquete `ri2`

Partir replicando lo mismo que antes (llegar al mismo p-value) \`

```{r}
library(ri2)
```

"In order to conduct randomization inference, we need to supply 1) a test statistic, 2) a null hypothesis, and 3) a randomization procedure."

El procedimiento de randomizacion: tiene que corresponder con como se asigno el tratamiento en primer lugar. Funcion `declare_ra` permite declarar este procedimiento.

```{r}
declaration <- declare_ra(N = 8, m = 4)
declaration
```

<https://stackoverflow.com/questions/19544254/permutation-test-in-r-and-seeing-which-assignments-lead-to-greater-outcome/48628402#48628402>

Para suministrar el estadistico del test, podemos usar el argumento `formula` de la funcion `conduct_ri`. Tambien se puede usar argumento `test_function`: debe ser funcion que recibe un data frame y retorna un escalar (el valor del test).

`sharp_hypothesis`: valor del treatment effect bajo la sharp null. Admite un numero escalar.

```{r}
# Declarando la `test_function`
sdo <- function(data) {
  data %>% 
  summarise(te1 = mean(y[d == 1], na.rm=TRUE),
            te0 = mean(y[d == 0], na.rm=TRUE),
            sdo = te1 - te0) %>% 
    pull(sdo) %>% 
    abs()
}
```

```{r}
ri2_out <- conduct_ri(
  test_function = sdo,
  assignment = "d",
  outcome = "y",
  declaration = declaration,
  sharp_hypothesis = 0,
  data = ri
)

summary(ri2_out)
```

```{r}
# Ambos metodos han generado el mismo set de estadisticos
all(ri2_out$sims_df$est_sim %in% perms_ranked$sdo)
```

```{r}
all.equal(ri2_out$sims_df$est_sim %>% table(),
          perms_stats$sdo %>% table())
# OK, con esto me consta que el conjunto de permutaciones obtenidos son los mismos
# Pero porque hay una diferencia con los p-values!!!!???
```

```{r}
perms_stats
```

```{r}
ri2_out <- conduct_ri(
  formula = y ~ d,
  assignment = "d",
  outcome = "y",
  declaration = declaration,
  sharp_hypothesis = 0,
  data = ri,
  p = "upper",
  sims = 70
)

summary(ri2_out)
```

```{r}
plot(ri2_out)
```

CHALLENGE: Como utilizar el estadistico KS usando test_function?

```{r}
# Declaramos que tratamiento se asigna a 2 unidades de 7
declaration <- declare_ra(N = 7, m = 2)

# Conduct Randomization Inference
ri2_out <- conduct_ri(
  # Estadistico del test: diferencia de medias
  formula = Y ~ Z,
  declaration = declaration,
  # Sharp null tradicional
  sharp_hypothesis = 0,
  # Dataset con los D e Y observados
  data = table_2_2
)

summary(ri2_out)
```

```{r}
plot(ri2_out)
```

"A major benefit of randomization inference is we can specify any scalar test statistic, which means we can conduct hypothesis tests for estimators beyond the narrow set for which statisticians have derived the variance."

"Randomization inference is a useful tool because we can conduct hypothesis tests without making additional assumptions about the distributions of outcomes or estimators. We can also do tests for arbitrary test statistics -- we're not just restricted to the set for which statisticians have worked out analytic hypothesis testing procedures."

<https://cran.r-project.org/web/packages/ri2/vignettes/ri2_vignette.html>
