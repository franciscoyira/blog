---
title: 'Randomization Inference en R: una mejor forma de calcular p-values en experimentos aleatorios'
author: Francisco Yir치
date: '2022-01-21'
slug: randomization-inference-causal-mixtape
cover: "images/dices.jpg"
useRelativeCover: true
coverCaption: "Cr칠ditos de la imagen a [Bert Brus](https://www.bertbrus.nl/)"
isMath: "true"
categories:
  - inferencia-causal
  - libros
  - data-science
  - R
tags:
  - causal-inference-the-mixtape
  - resumenes
  - p-values
  - tutorial
  - portfolio
---

Bienvenidos a un nuevo art칤culo de [la serie](https://www.franciscoyira.com/es/tags/causal-inference-the-mixtape/) dedicada al libro [**Causal Inference: The Mixtape**](https://mixtape.scunning.com/). En el art칤culo anterior vimos una introducci칩n a [la notaci칩n de outcomes potenciales](https://www.franciscoyira.com/es/post/potential-outcomes-causal-inference-mixtape/) y lo importante que es esta para expresar conceptos de causalidad, tales como la posibilidad de usar la diferencia de medias en experimentos aleatorizados como estimador insesgado de efectos causales.

TODO: RESUMIR M츼S LA INTRODUCCI칍N

Sin embargo, un par de conceptos que estuvieron totalmente ausentes en ese art칤culo fueron los de test de hip칩tesis y varianza. Hablamos de que la diferencia simple de medias (SDO por sus siglas en ingl칠s) ten칤a la misma *esperanza* que el efecto causal promedio (ATE) cuando la asignaci칩n del tratamiento (D) era independiente de los outcomes potenciales ($Y_i^1, Y_i^0$).

Pero en el mundo real no observamos la esperanza sino que realizaciones particulares: dos monedas tienen la misma esperanza de arrojar cara o sello al ser lanzadas, pero si lanzamos cada una 5 veces, es muy probable que el n칰mero de caras y sellos difiera entre ellas, simplemente debido a la fluctuaci칩n aleatoria o varianza propia de este proceso generador de datos.

Dada esa variabilidad en la diferencia de medias, 쯤u칠 tan grande debe ser este valor observado para que estemos seguros de que existe una diferencia *real* entre el grupo tratado y el grupo de control? (es decir, una diferencia en las esperanzas).

Esta pregunta usualmente se responde realizando un test de medias/regresi칩n lineal/ANOVA. Estos m칠todos son ampliamente ense침ados en los cursos universitarios de estad칤stica y econometr칤a, y existe sobre mucho material disponible en internet para aprenderlos, as칤 que este post no se centra en ellos.

De lo que hablaremos hoy ser치 de una metodolog칤a alternativa a los tests de hip칩tesis tradicionales para experimentos aleatorizados. Esta metodolog칤a se llama **randomization inference**, y tambi칠n responde la pregunta de *qu칠 tan distintos deben ser los valores de tratados y controles*, pero de una forma distinta.

## 쯇or qu칠 molestarse en aprender esto?

Una pregunta que quiz치s te estes haciendo en este momento es porque valdr칤a la pena invertir tiempo en aprender y aplicar randomizacion inference siendo que ya contamos con tests de hip칩tesis tradicionales que son ampliamente usados y conocidos. Yo me estar칤a preguntando lo mismo si estuviera en tu lugar.

Las razones para aplicar randomizacion inference en nuestros tests de hip칩tesis pueden resumirse en las siguientes:

1.  Al hacer inferencia causal con datos experimentales, la principal fuente de incertidumbre no es el muestreo desde una poblaci칩n mas grande sino que la asignaci칩n aleatoria del tratamiento combinada con la imposibilidad de conocer los contrafactuales. Los metodos tradicionales de test de hip칩tesis no toman esto en consideraci칩n, sino que se enfocan en la incertidumbre de muestreo. **Esto es particularmente problem치tico si trabajamos con grandes datasets administrativos que literalmente representan "toda la data"** (a.k.a. bIg dAtA) tales como A/B testings, y puede traducirse en que subestimemos considerablemente la incertidumbre en nuestros resultados. Randomization inference aborda estos problemas al tomar en cuenta la incertidumbre proveniente de la asignaci칩n del tratamiento, por lo que resulta un procedimiento mas apropiado en estos casos.

2.  Tambi칠n existen ventajas al estar en el extremo opuesto: datos peque침os y/o muy pocas unidades tratadas. En esto casos no resulta muy cre칤ble apelar a las propiedades de "muestras grandes" en las que se basan los tests convencionales. En particular, podemos sufrir de una alta vulnerabilidad a o utileros y observaciones de alto leverage, lo cual se traduce en riesgo de over-rejection de la hip칩tesis nula. Randomization inference nos ayuda en tal situaci칩n al ser una metodolog칤a m치s robusta a outliers y observaciones de alto leverage.

3.  Finalmente, aun si no existe ning칰n problema particular con los tests tradicionales, randomization inference nos entrega mucha mas libertad respecto de los estimadores o estad칤sticos a usar. Mientras que al hacer un test de medias habitual estamos restringidos a aquellos estimadores para los cuales se ha podido derivar la varianza, randomization inference nos abre las puertas para usar cualquier estad칤stico escalar que pueda obtenerse a partir de un dataset. Algunos ejemplos 칰tiles son los estad칤sticos en base a quintiles (por ejemplo, la mediana), en base a rankings, o el estad칤stico KS (Kolmogorov-Smirnov) que mide diferencias en las funciones de distribuci칩n acumuladas.

Y como bonus, hacer randomization inference es cool. En el mundo de la inferencia causal existe una preferencia est칠tica por las metodolog칤as de "placebo" que simulan tratamientos falsos en los datos reales y chequear que *no* encontremos un efecto relevante de este tratamiento falso, y asi estar mas seguros de que nuestras conclusiones sobre el tratamiento verdadero son validas[^1]. M치s abajo veremos que randomization inference consiste en algo muy similar a esto.

[^1]: Algunas de las metodolog칤as de inferencia causal que se apalancan mucho en tests de placebo son regresi칩n discontinua y diferencias en diferencias. En art칤culos posteriores entrar칠 en mas detalle al respecto.

"A major benefit of randomization inference is we can specify any scalar test statistic, which means we can conduct hypothesis tests for estimators beyond the narrow set for which statisticians have derived the variance."

"Randomization inference is a useful tool because we can conduct hypothesis tests without making additional assumptions about the distributions of outcomes or estimators. We can also do tests for arbitrary test statistics -- we're not just restricted to the set for which statisticians have worked out analytic hypothesis testing procedures."

## En qu칠 consiste randomization inference, y c칩mo aplicarlo en R

Primero que todo, volver칠 a enfatizar el objetivo y contexto en el cual aplicamos este procedimiento: estamos analizando datos provenientes de un experimento aleatorizado y tenemos

-   Un conjunto de observaciones que fueron asignadas aleatoriamente a grupos de tratamiento y control

-   Una variable de resultados (Y)

Y queremos determinar **si el tratamiento tiene alg칰n efecto sobre dicha variable de resultados**.

Ya que casi siempre existir치n diferencias entre el grupo tratado y el grupo de control (simplemente por la variabilidad natural del proceso generador de datos), es necesario realizar alg칰n test de hip칩tesis para determinar si las diferencias observadas son lo suficientemente grandes como para ser consideradas evidencia de un efecto causal.

Estando en esta situaci칩n, podemos aplicar **randomization inference** mediante aplicar los siguientes pasos.

### Paso 1: escoger una hip칩tesis nula "sharp"

En un test de hip칩tesis tradicional tenemos una hip칩tesis nula que afirma algo respecto a un par치metro poblacional, por ejemplo, $\beta_1=0$ donde $\beta_1$ es el coeficiente asociado a la variable de tratamiento $D$.

Lo que esta hip칩tesis nula plantea es que el efecto *promedio* del tratamiento es 0, pero no dice nada acerca de los efectos del tratamiento para cada unidad $\delta_i$.

En cambio, al aplicar randomization inference utilizamos una hip칩tesis nula *sharp*, es decir, una nula que afirme algo sobre cada una de las unidades.

La m치s usada y conocida es la **sharp null de Fischer**:

$$
\delta_i=0
$$

Que nos plantea que el tratamiento tiene efecto cero para todas las unidades analizadas.

Para efectos de simplicidad, en este post se usar치 la sharp null de Fischer, pero notar que podr칤amos perfectamente testear hip칩tesis alternativas tales como $\delta_i=1$, $\delta_i=2$, etc. Incluso podr칤amos testear hip칩tesis en las que diferentes grupos o unidades tengan valores de $\delta_i$ distintos. Lo 칰nico que se requiere es tener una hip칩tesis que plantee algo respecto de cada uno de los $\delta_i$.

쯈u칠 ganamos con usar una nula de este tipo? Pues que nos permite **completar las columnas de Potential Outcomes en nuestro dataset**.

Los datos que observamos normalmente tienen esta estructura:

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(magrittr)
library(causaldata)

ri <- causaldata::ri %>% 
  mutate(id_unit = row_number(),
         y0 = as.numeric(y0),
         y1 = as.numeric(y1))

ri
```

Para todas las unidades observamos $D_i$ e $Y_i$, pero solo uno de los outcomes potenciales ($Y_i^0$ o $Y_i^1$). Apalanc치ndonos en la sharp null, podemos completar las columnas `y0` e `y1`.

```{r}
ri_fischer_null <- ri %>% 
  mutate(y0 = y,
         y1 = y)

ri_fischer_null
```

Como estamos asumiendo que el tratamiento tiene un efecto igual a cero para todas las unidades, ambos outcomes potenciales son iguales al outcome observado.

Por supuesto, no estamos afirmando realmente que esto sea as칤, simplemente queremos descubrir qu칠 tan improbable es haber observado las diferencias entre grupos que estamos observando bajo el supuesto de esta "sharp null".

### Paso 2: escoger un estad칤stico de test

Para realizar un test de hip칩tesis necesitamos no solo una hip칩tesis nula sino que tambi칠n un **estad칤stico**. En un test de hip칩tesis tradicional, ser칤a necesario que este estad칤stico cuente con un estimador para su varianza, pero al aplicar randomization inference podemos usar literalmente cualquier estad칤stico escalar que pueda obtenerse a partir de un vector de asignaciones de tratamiento ($D$) y de un vector de outcomes ($Y$).

Uno de los estad칤sticos m치s simples que podemos usar es la **diferencia simple de medias (SDO)** entre ambos grupos.

```{r}
# Funcion que define el estad칤stico: recibe como input un dataframe con 
# las columnas y (outcome) y d (asignacion de tratamiento), y retorna un 
# valor escalar
sdo <- function(data) {
  data %>%
    summarise(te1 = mean(y[d == 1]),
              te0 = mean(y[d == 0]),
              sdo = te1 - te0) %>%
    pull(sdo)
}

sdo(ri_fischer_null)
```

Sin embargo, nada impide usar otros estad칤sticos de test (esta libertad es de hecho una de las principales ventajas de aplicar randomization inference).

Algunos ejemplos de estad칤sticos alternativos que podr칤amos usar son:

-   **Estad칤sticos de quantiles**, por ejemplo la diferencia de medianas entre grupos (o cualquier otro percentil). 칔tiles si tenemos outliers u observaciones de alto leverage.

-   **Estad칤sticos de ranking**, que convierten la variable de outcomes ($Y$) en valores de ranking (1 para el outcome m치s bajo, 2 para el segundo m치s bajo, etc) y luego computan una m칠trica en base a esos rankings (por ejemplo, diferencia de medias o de medianas).

-   **Estad칤stico KS (Kolmogorov-Smirnov)**, permite identificar diferencias en las distribuciones de los outcomes mediante medir la distancia m치xima entre ambas funciones de distribuci칩n acumuladas. Este estad칤stico nos permitir칤a, por ejemplo, detectar el efecto de un tratamiento que no cambie la media de la variable de resultados, pero s칤 su varianza o dispersi칩n.

Para mantener la simplicidad, a continuaci칩n se usar치 el SDO como estad칤stico de test, pero m치s abajo mostrar칠 ejemplos de c칩digo utilizando otros estad칤sticos.

### Paso 3: simular distintas asignaciones de tratamiento y obtener la distribuci칩n del estad칤stico

El siguiente paso consiste en obtener la distribuci칩n de valores que podr칤a tomar el estad칤stico del test bajo la "sharp" null.

Para esto:

1.  Realizaremos permutaciones en el vector $D$ usando el mismo proceso aleatorio que se utiliz칩 para obtener las asignaciones de tratamiento "originales" o "verdaderas". Por ejemplo, si para asignar el tratamiento se us칩 un proceso equivalente a lanzar una moneda al aire para cada observaci칩n ($B(n, 0.5)$), entonces cada una de las permutaciones deben provenir del mismo proceso.[^2]

    En nuestro ejemplo, el proceso consiste en sortear 4 asignaciones de tratamiento para un total de 8 observaciones, lo cual produce 70 permutaciones posibles en total.

    ```{r}
    perms <- t(combn(ri_fischer_null$id_unit, 4)) %>% asplit(1) 

    perms_df <- 
      tibble(treated_units = perms) %>% 
      transmute(id_perm = row_number(),
                treated_units = map(treated_units, unlist))

    ri_permuted <- 
      crossing(perms_df, ri_fischer_null) %>% 
      mutate(d = map2_dbl(id_unit, treated_units, ~.x %in% .y))

    ri_permuted
    ```

    ```{r}
    ri_permuted %>% 
      pull(id_perm) %>% 
      n_distinct()
    ```

2.  Para cada permutaci칩n, simulamos los valores de $Y$ en base a la hip칩tesis nula escogida en el Paso 1. **Para la sharp null de Fischer literalmente no hay que hacer nada**, porque plantea que $Y_i=Y_i^0=Y_i^1$, es decir, que el vector de outcomes habr칤a sido el mismo independiente de cual hubiera sido la asignaci칩n del tratamiento (pero si nuestra *sharp* null fuera algo como $\delta_i=1$ entonces s칤 habr칤a que cambiar los valores de $Y$ con cada permutaci칩n de $D$).

3.  Calcularemos el valor del estad칤stico (escogido en el paso anterior) para cada una de estas permutaciones y guardamos su valor.

    ```{r}
    perms_stats <- 
      ri_permuted %>%
      group_by(id_perm) %>%
      summarise(te1 = mean(y[d == 1]),
                te0 = mean(y[d == 0]),
                sdo = te1 - te0)

    perms_stats %>% 
      select(id_perm, sdo)
    ```

4.  Listo! Los valores del estad칤stico obtenidos en (3) nos indican la distribuci칩n de este bajo la *sharp* null.

    ```{r, message=FALSE}
    ggplot(perms_stats, aes(sdo)) +
      geom_histogram() +
      labs(x = "Estad칤stico del test (SDO)")
    ```

[^2]: Si se us칩 clustering o blocking por grupos al hacer la randomizaci칩n, tambi칠n debe usarse al obtener las permutaciones.

**쮺u치ntas permutaciones se debe realizar?** Lo ideal ser칤a agotar todas permutaciones posibles para conseguir una representaci칩n exacta de la distribuci칩n del estad칤stico de test bajo la *sharp* null. Sin embargo, esto solo es factible en datasets muy peque침os: incluso con un dataset de 2000 observaciones ya se vuelve computacionalmente prohibitivo obtener todas las combinaciones posibles del vector $D$.

La alternativa en ese caso es conformarnos con hacer las permutaciones suficientes para obtener una aproximaci칩n razonable a la distribuci칩n del estad칤stico[^3].

[^3]: Como referencia, la funci칩n `ri2::conduct_ri`, que es una de las implementaciones de randomization inference que existen R, realiza 1000 simulaciones/permutaciones por defecto.

### Paso 4: comparar el estad칤stico "real" con la distribuci칩n simulada para obtener el p-value

Luego de haber obtenido la distribuci칩n del estad칤stico bajo la *sharp* null (exacta o aproximada), procedemos a ubicar el estad칤stico "verdadero" (aquel correspondiente los valores reales de $D$ e $Y$) dentro de esa distribuci칩n.

*Notar que si queremos realizar un test de dos colas (lo m치s usual) debemos aplicar valor absoluto a la distribuci칩n de estad칤sticos (que es de hecho lo que hacemos en este ejemplo).*

```{r, message=FALSE}
true_statistic <- perms_stats %>% 
  filter(id_perm == 1) %>% 
  pull(sdo)

ggplot(perms_stats, 
       # Aplicamos valor absoluto porque haremos un test de 2 colas
       aes(abs(sdo))) +
  geom_histogram() +
  labs(x = "Valor absoluto del estad칤stico del test (|SDO|)") +
  geom_vline(xintercept = true_statistic, colour = "red", size = 2) +
  annotate(geom = "label",
           x = true_statistic,
           y = 10,
           label = "Estad칤stico 'verdadero'",
           colour = "red") +
  annotate("segment", x = true_statistic+1, xend = true_statistic+3, y = 9, yend =9,
           colour = "purple", size = 2, arrow = arrow()) +
  annotate(geom = "label",
           x = true_statistic+2,
           y = 10,
           label = "Estad칤sticos m치s extremos",
           colour = "purple")
```

Y con ello podemos calcular el **p-value** (que es lo que hemos estado buscando desde un comienzo).

Este p-value se calcula en dos pasos:

1.  Se obtiene **el ranking descendiente de los estad칤sticos de test** de las permutaciones (el con mayor valor tiene ranking 1 y el con menor valor tiene ranking N). Para los estad칤sticos que tienen el mismo valor, su ranking es el m치ximo de los ranking originales de los estad칤sticos que comparten ese valor (por ejemplo, si tres estad칤sticos tienen ranking 2, 3, y 4, todos ellos quedan con ranking igual a 4).

2.  Se calcula el ratio entre el ranking del estad칤stico verdadero y el total de permutaciones obtenidas (N).

```{r}
perms_ranked <- perms_stats %>%
  # Igual que antes, se aplica valor absoluto para tener un test de dos colas
  mutate(abs_sdo = abs(sdo)) %>% 
  select(id_perm, abs_sdo) %>% 
  arrange(desc(abs_sdo)) %>% 
  mutate(rank = row_number(desc(abs_sdo))) %>% 
  group_by(abs_sdo) %>% 
  mutate(new_rank = max(rank))

perms_ranked
```

```{r}
n <- nrow(perms_ranked)

p_value <- 
  perms_ranked %>% 
  filter(id_perm == 1) %>%
  pull(new_rank)/n

p_value
```

En nuestro caso, el p-value obtenido es de 0.86, lo que implica que no podemos rechazar la *sharp* null con un 5% de significancia (ni con un 10 ni un 20 ni un 30 游땐). Dicho de otra forma, **el valor de SDO observado no es un valor improbable de observar si asumimos que el tratamiento no tuvo efecto en ninguna unidad** y que la 칰nica fuente de variabilidad en el estad칤stico es la asignaci칩n aleatoria de $D$.

## Haci칠ndolo m치s f치cil con el paquete *ri2* 游뱅

El c칩digo en R mostrado arriba ten칤a como fin explicar en qu칠 consiste cada paso del procedimiento. Sin embargo, no es muy conciso y adaptarlo para otros datasets puede resultar un poco tedioso. Por ello, para aplicar randomization inference en nuestros propios datos es recomendable usar paquetes de R dise침ados para este fin, tales como `ri2`.

```{r, message=FALSE}
library(ri2)
```

Algo que no cambia respecto al c칩digo "manual" es que siempre debemos suministrar 1) un estad칤stico de test, 2) una hip칩tesis nula *sharp*, y 3) un procedimiento de randomizaci칩n. E igual que antes, el procedimiento de randomizaci칩n indicado en el c칩digo debe ser id칠ntico al que se utiliz칩 para asignar el tratamiento en primer lugar.

Para declarar el procedimiento de randomizaci칩n se usa la funci칩n `ri2::declare_ra`. En este caso (igual que en el ejemplo de antes) estamos declarando la asignaci칩n aleatoria de 4 unidades tratadas (`m = 4`) dentro de una muestra de 8 unidades (`N = 8`).

```{r}
declaration <- declare_ra(N = 8, m = 4)
declaration
```

Podemos suministrar el estad칤stico del test mediante el argumento `formula` de la funci칩n `ri2::conduct_ri`. Si nuestro estad칤stico es simplemente la diferencia de medias entre tratados y controles, la f칩rmula a utilizar ser치 algo como `y ~ d` (con `y` como variable de outcome y `d` como variable de asignaci칩n de tratamiento).

Alternativamente, podemos especificar el estad칤stico mediante el argumento `test_function`, que admite cualquier funci칩n de R capaz de recibir un dataframe y retornar un escalar (i.e., el valor del estad칤stico de test).

```{r}
# Declarando la `test_function`
sdo <- function(data) {
  data %>% 
  summarise(te1 = mean(y[d == 1], na.rm=TRUE),
            te0 = mean(y[d == 0], na.rm=TRUE),
            sdo = te1 - te0) %>% 
    pull(sdo)
}
```

En tanto, la hip칩tesis nula *sharp* se especifica mediante el argumento `sharp_hypothesis` de la misma funci칩n `ri2::conduct_ri`. Su valor por defecto es 0, as칤 que si vamos a usar la *sharp* null de Fischer podemos omitirlo.

Finalmente, combinamos todos estos "ingredientes" en la funci칩n `conduct_ri` e inspeccionamos los resultados con la funci칩n `summary`.

```{r}
ri2_out <- conduct_ri(
  test_function = sdo,
  assignment = "d",
  outcome = "y",
  declaration = declaration,
  sharp_hypothesis = 0,
  data = ri
)

summary(ri2_out)
```

Como vemos, el p-value retornado por `ri2::conduct_ri` es id칠ntico al que obtuvimos ejecutando el c칩digo de la secci칩n anterior, pero con la ventaja de que el c칩digo de `ri2` es mucho m치s conciso y legible.

Otra ventaja de `ri2::conduct_ri` es que su output puede ser graficado directamente con la funci칩n `plot()`.

```{r, message=FALSE}
plot(ri2_out)
```

Este gr치fico es incluso mejor que el creado a mano en la secci칩n anterior porque destaca autom치ticamente los estad칤sticos que son tan o m치s extremos que el estad칤stico simulado, y representa apropiadamente los tests de dos colas sin tener que transformar los estad칤sticos a valor absoluto.

Adem치s, dado que el output de `plot(ri2_out)` es un objeto de ggplot2, podemos personalizar el gr치fico usando las funciones de ggplot2 que ya conocemos. Por ejemplo, podemos aplicarle un tema de `ggthemes`:

```{r, warning=FALSE}
plot(ri2_out) +
  ggthemes::theme_stata()
```

Si queremos inspeccionar manualmente la data de las simulaciones, es posible hacerlo extrayendo el dataframe `sims_df` desde el output de `ri2::conduct_ri`. Este dataframe tendr치 tantas filas como permutaciones de $D$ se hayan efectuado.

```{r}
ri2_out[["sims_df"]] %>% head()
```

### Bonus: usando el estad칤stico KS para medir diferencias en distribuciones de outcomes

Una de las ventajas de randomization inference mencionadas al comienzo de este post era la posibilidad de utilizar estad칤sticos alternativos, siendo el 칰nico requisito sobre estos el que correspondan a valores escalares obtenidos a partir de $D$ e $Y$.

Uno de los estad칤sticos "alternativos" es m치s interesantes (en mi opini칩n) es el **estad칤stico KS** (Kolmogorov-Smirnov) que mide la diferencia m치xima entre dos funciones de distribuci칩n acumuladas emp칤ricas (en este caso, entre la de las unidades tratadas $\hat{F_T}$ y la de las unidades de control $\hat{F_C}$):

$$
T_{KS}=\max|\hat{F_T}(Y_i) - \hat{F_C}(Y_i)|
$$

Lo cual se puede apreciar visualmente en el siguiente gr치fico de ejemplo, donde el valor del estad칤stico corresponde al largo de la l칤nea roja punteada.

![*Ejemplo de estad칤stico KS con 2 funciones de distribuci칩n acumuladas. Fuente: [StackExchange](https://stats.stackexchange.com/questions/208517/kolmogorov-smirnov-test-vs-t-test)*](images/ks_example.png)

**쯇or qu칠 querr칤amos usar el estad칤stico KS en vez de algo m치s familiar, como la diferencia de medias?**

Pues porque puede haber casos en que el tratamiento afecte la distribuci칩n de los outcomes, pero sin generar cambios importantes en la media, por ejemplo aumentando la dispersi칩n, o generando una distribuci칩n bimodal:

```{r, warning=FALSE}
tb <- tibble(
  d = c(rep(0, 20), rep(1, 20)),
  y = c(0.22, -0.87, -2.39, -1.79, 0.37, -1.54, 
        1.28, -0.31, -0.74, 1.72, 
        0.38, -0.17, -0.62, -1.10, 0.30, 
        0.15, 2.30, 0.19, -0.50, -0.9,
        -5.13, -2.19, 2.43, -3.83, 0.5, 
        -3.25, 4.32, 1.63, 5.18, -0.43, 
        7.11, 4.87, -3.10, -5.81, 3.76, 
        6.31, 2.58, 0.07, 5.76, 3.50)
)

kdensity_d1 <- tb %>%
  filter(d == 1) %>% 
  pull(y)
kdensity_d1 <- density(kdensity_d1)

kdensity_d0 <- tb %>%
  filter(d == 0) %>% 
  pull(y)
kdensity_d0 <- density(kdensity_d0)

kdensity_d0 <- tibble(x = kdensity_d0$x, y = kdensity_d0$y, d = 0)
kdensity_d1 <- tibble(x = kdensity_d1$x, y = kdensity_d1$y, d = 1)

kdensity <- full_join(kdensity_d1, kdensity_d0,
                      by = c("x", "y", "d"))
kdensity$d <- as_factor(kdensity$d)

ggplot(kdensity)+
  geom_point(size = 0.3, aes(x,y, color = d))+
  xlim(-7, 8)+
  scale_color_discrete(labels = c("Control", "Treatment"))
```

En el ejemplo de arriba, si hacemos randomization inference usando el SDO como estad칤stico no podemos descartar la *sharp* null de que el efecto del tratamiento es cero para todas las unidades, a pesar de que claramente las distribuciones son muy distintas.

```{r}
set.seed(1989)

conduct_ri(
  test_function = sdo,
  assignment = "d",
  outcome = "y",
  declaration = declare_ra(N = 40, m = 20),
  sharp_hypothesis = 0,
  data = tb,
  sims = 10000
)
```

Veamos qu칠 resultado obtenemos al usar el estad칤stico KS en vez del SDO:

```{r}
# Declarando la funci칩n que obtiene el estad칤stico KS a partir de un dataframe
ks_statistic <- function(data) {
  
  control <- data[data$d == 0, ]$y
  treated <- data[data$d == 1, ]$y
  
  cdf1 <- ecdf(control) 
  cdf2 <- ecdf(treated)
  
  minMax <- seq(min(control, treated),
                max(control, treated),
                length.out=length(c(control, treated))) 
  
  x0 <-
    minMax[which(abs(cdf1(minMax) - cdf2(minMax)) == max(abs(cdf1(minMax) - cdf2(minMax))))]
  
  y0 <- cdf1(x0)
  y1 <- cdf2(x0) 
  
  diff <- unique(abs(y0 - y1))
  
  diff
  
}

# obteniendo el p-value con randomization inference
set.seed(1989)

ri_ks <-
  conduct_ri(
    test_function = ks_statistic,
    assignment = "d",
    outcome = "y",
    declaration = declare_ra(N = 40, m = 20),
    sharp_hypothesis = 0,
    data = tb,
    sims = 10000
  )

ri_ks
```

El estad칤stico KS s칤 permite rechazar correctamente la nula de efecto 0 a un nivel de significancia del 5%.

En la siguiente figura podemos visualizar el estad칤stico KS correspondiente al vector $D$ verdadero, junto con las CDF emp칤ricas de los grupos de tratamiento y control.

```{r}
tb2 <- tb %>%
group_by(d) %>%
arrange(y) %>%
mutate(rn = row_number()) %>%
ungroup()


cdf1 <- ecdf(tb2[tb2$d == 0, ]$y) 
cdf2 <- ecdf(tb2[tb2$d == 1, ]$y) 

minMax <- seq(min(tb2$y),
              max(tb2$y),
              length.out=length(tb2$y)) 

x0 <- 
  minMax[which(abs(cdf1(minMax) - cdf2(minMax)) == max(abs(cdf1(minMax) - cdf2(minMax))) )] 

y0 <- cdf1(x0) 
y1 <- cdf2(x0) 

ggplot(tb2) +
  geom_step(aes(x=y, y=rn, color=factor(d)),
            size = 1.5, stat="ecdf") +
  labs(y = "Densidad") +
  geom_segment(aes(x = x0[1], y = y0[1], xend = x0[1], yend = y1[1]),
               linetype = "dashed", color = "red", size = 1) +
  geom_point(aes(x = x0[1] , y= y0[1]), color="red", size=4) +
  geom_point(aes(x = x0[1] , y= y1[1]), color="red", size=4)
```

## Consideraciones y referencias adicionales 游댌游닄

Para concluir, quiero comentar algunos detalles adicionales y consideraciones respecto a esta metodolog칤a:

-   Para obtener **intervalos de confianza** con randomization inference podemos crear un vector con un rango de valores posibles para el estad칤stico del test (ej, 0.1, 0.2, 0.3, etc) y usar cada uno de ellos como *sharp* null mediante iteraci칩n. El intervalo de confianza estar치 compuesto de todos aquellos valores para los cuales la *sharp* null no se rechace.

-   En el libro Causal Inference: The Mixtape se nos advierte que randomization inference presenta cierto **sesgo en contra de los efectos peque침os cuando se usa junto a la sharp null de Fischer**. Esto debido a que solo treatment effects relativamente grandes permitir치n rechazar esta nula a niveles convencionales de significancia. Por ende, si el efecto esperado de nuestro tratamiento es peque침o, nos conviene buscar estad칤sticos alternativos, agregar covariates que expliquen la variable de outcome (esto se puede hacer con el argumento `formula` de `ri2::conduct_ri`), o directamente no usar randomization diference.

-   Otra cr칤tica que existe hacia esta metodolog칤a es que, seg칰n algunos, [la *sharp* null representa una hip칩tesis "poco interesante y acad칠mica"](https://youtu.be/XUh8KsaWfJ4?t=546), ya que la idea de un efecto constante para todas las unidades ser칤a demasiado restrictiva. En respuesta a eso, [en esta conferencia online de Xinran Li](https://youtu.be/XUh8KsaWfJ4?t=807) se plantea la idea de generalizar el procedimiento para obtener quantiles de efectos individuales, y as칤 llegar a conclusiones tales como "el X% de las unidades experimenta un efecto causal superior a Y".

Finalmente, compartirles un par de **referencias** en caso de que deseen profundizar m치s.

-   [La vignette del paquete `ri2`](https://cran.r-project.org/web/packages/ri2/vignettes/ri2_vignette.html) contiene ejemplos de c칩mo usar sus funciones para dise침os experimentales m치s complejos, tales como cuando se prueban varios tratamientos al mismo tiempo, se quiere evaluar interacciones con covariables, o se hace randomizaci칩n con clustering o blocking por grupos.

-   [Este apunte de Mathew Blackwell](https://www.mattblackwell.org/files/teaching/s05-fisher.pdf) resume muy bien los conceptos de randomization inference, por lo que resulta buen material de consulta o repaso (de hecho me apoye en 칠l para escribir este art칤culo, junto con [el cap칤tulo 4 de Causal Inference: The Mixtape](https://mixtape.scunning.com/potential-outcomes.html#randomization-inference)).

*Tu feedback es bienvenido. Si tienes comentarios sobre este art칤culo puedes envi치rmelos [por correo](mailto:francisco.yira@outlook.com).*
