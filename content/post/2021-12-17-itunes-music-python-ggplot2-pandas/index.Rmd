---
title: 'iTunes Wrapped: analyzing my music data with Python and ggplot2'
author: Francisco Yirá
date: '2021-12-17'
slug: itunes-music-python-ggplot2-pandas
categories:
  - data-science
  - python
  - portfolio
  - R
tags:
  - music
  - pandas
  - data-viz
  - data-wrangling
  - matplotlib
  - seaborn
  - XML
---

```{r setup, include=FALSE}
# knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
knitr::knit_engines$set(python = reticulate::eng_python)
```

```{python load-packages}
import pandas as pd
import numpy as np
from lxml import objectify
import xml.etree.ElementTree as ET
import requests
import seaborn as sns
import matplotlib
matplotlib.use('Agg')
from matplotlib import pyplot as plt
from matplotlib import style
import os
import re
```


```{python download-xml}
if not os.path.isfile('iTunes.xml'):
  path = 'https://onedrive.live.com/download?cid=59E4C7D110DACCCC&resid=59E4C7D110DACCCC%21595580&authkey=AM93Z8YvAb4JiBY'
  r = requests.get(path, allow_redirects=True)
  open('iTunes.xml', 'wb').write(r.content)
  

```


```{python load-xml}
tree = ET.parse('iTunes.xml')
```


```{python explore-root}
root = tree.getroot()
root.tag
```
This iterates over the main dict (the element that comes after 'plist') until it finds the tracks dict (the first nested dict). Then it saves is it in tracks_dict.
```{python}
main_dict=root.findall('dict')

for item in list(main_dict[0]):  
    print("element type:", item.tag)
    if item.tag=="dict":
        print('BINGO!')
        tracks_dict=item
        break

```

At this point, tracks_dict is a dict of dicts, and each dict represents a track from my music collection. Let's convert this dict into a list
```{python}
tracklist=list(tracks_dict.findall('dict'))
tracklist[0:5]
```
The length of this list matches the number of songs in my music collection:
```{python}
len(tracklist)
```

Also, the `tracks_dict` dict contains `key` elements, which are unique IDs for each song (I assume):
```{python}
tracks_ids=list(tracks_dict.findall('key'))

for i in tracks_ids[:5]:
  print(i.text)

```
Retrieve the different kinds of media that exists in the collection:
```{python}
kinds=set([])
for i in range(len(tracklist)):
  for j in range(len(tracklist[i])):
    if (tracklist[i][j].tag=="key" and tracklist[i][j].text=="Kind"):
      kinds.add(tracklist[i][j+1].text)

kinds=pd.Series(list(kinds))
kinds
```
The ones I want are:

* Archivo de audio AAC comprado
* Purchased AAC audio file
* Archivo de audio MPEG
* Apple Lossless audio file
* Audio Apple Lossless
* Archivo de audio AAC

The others are either music videos or audibooks
```{python}
kinds_i_want = pd.Series(['Archivo de audio AAC comprado',
                          'Purchased AAC audio file',
                          'Archivo de audio MPEG',
                          'Apple Lossless audio file',
                          'Audio Apple Lossless',
                          'Archivo de audio AAC'])
```

Obtaining the set of attributes for different kinds of media:
```{python}
# This code will retrieve all the keys of the first track of the corresponding
# Kind
def cols(kind):
    cols=[]
    kind_found=False
    for i in range(len(tracklist)):
        for j in range(len(tracklist[i])):
            # Whether the track is of the corresponding kind or not, 
            # I will store its columns
            if tracklist[i][j].tag=="key":
                cols.append(tracklist[i][j].text)
            # After finding the first track that matches the specified track,
            # return it and stop the loops 
            if (tracklist[i][j].text=="Kind" and tracklist[i][j+1].text==kind):
                kind_found=True
        if kind_found:
          return set(cols)
              
track_kind=cols('Archivo de audio AAC comprado')
track_kind
```

Here I got the columns corresponding to the different kinds.
```{python}
results = map(cols, kinds_i_want)
results_list = [list(item) for item in results]
```

Obtaining set with unique columns 
```{python}
flat_list=[]
for item in results_list:
  for sub_item in item:
    flat_list.append(sub_item)

unique_cols=set(flat_list)
unique_cols
```
There are 58 attributes in total:
```{python}
len(unique_cols)
```


Create global dataframe with superset of columns:
```{python}
df_tracks=pd.DataFrame(columns=unique_cols)

dict1={}

for song_i in range(len(tracklist)):
  for attribute_i in range(len(tracklist[song_i])):
    if tracklist[song_i][attribute_i].tag=="key":
      # this creates an entry in the dict with thekey(attribute)-value pair
      dict1[tracklist[song_i][attribute_i].text]=tracklist[song_i][attribute_i+1].text
  list_values=[i for i in dict1.values()]
  list_keys=[j for j in dict1.keys()]
  if dict1['Kind'] in kinds_i_want.unique():
    df_temp=pd.DataFrame([list_values],columns=list_keys)
    df_tracks=pd.concat([df_tracks,df_temp],axis=0,ignore_index=True,sort=True)

```


```{python}
df_tracks
```


## Exploration on the obtained dataframe
```{python}
df_tracks.groupby('Kind').size().sort_values(ascending=False)
```
```{python}
df_tracks.groupby('Year').size().sort_index(ascending=False)
```
```{python}
df_tracks.groupby('Disabled').size().sort_values(ascending=False)
```
```{python}
df_tracks.groupby('Skip Count').size().sort_values(ascending=False)
```
```{python}
df_tracks[df_tracks['Skip Count'].astype(int) >= 6][['Name', 'Album', 'Skip Count']]
```


```{python}
df_tracks.groupby('Track Type').size().sort_values(ascending=False)
```
```{python}
df_tracks.groupby('Bit Rate').size().sort_values(ascending=False)
```

## Answering questions

### 'Remote' songs
What are 'Remote' files in Track Type field?
```{python}
df_tracks.query('`Track Type`=="Remote"')['Name'].values[:15]
```
These are mainly workout remixes I purchased on the iTunes Store for running. I have them downloaded in a stand-alone MP3 player that I use when I run, but I don't like listening to them in any other context, so that's why they're not downloaded in my music collection.

Others are soundtracks songs (Interstellar, Doctor Who, etc). This is a similar situation: I don't want these songs to play when I'm listening to my whole collection in shuffle, or to appear in some Smart Playlists that I have.

Finally, there are cases where I bought a digital song, but then also purchased the CD and ripped it. Here I prefer to listen to the ripped song, since it has Lossless audio (vs 256kbps of the iTunes Store verion). 

### Most listened songs and albums

An obvious question to answer with this data is what are the most listened songs an albums (I will left artists for later, because I will need to parse that data due to the way iTunes handles collaborations between several artists).

Songs are easier, since no aggregation is needed:
```{python}
df_tracks[['Play Count']] = df_tracks[['Play Count']].apply(pd.to_numeric)
```


```{python}
top_songs=(df_tracks
  .sort_values(by='Play Count', ascending=False)
  [['Name', 'Artist', 'Play Count', 'Genre']]
  .head(10))
  
```


```{python plot-top-songs}
plt.clf()
ax=sns.barplot(x='Play Count',
            y='Name',
            hue='Artist',
            data=top_songs,
            # TIL: how to disable nesting when using hue https://stackoverflow.com/questions/63365569/how-to-disable-the-nesting-made-by-hue-in-seaborn
            dodge=False,
            palette=sns.color_palette("Set1", 3))
# Rotating labels trying to make them fit
ax.figure.set_size_inches(7,5)
ax.xaxis.grid(True)  
ax.set(ylabel='Track')
plt.tight_layout()
plt.savefig('test.png', dpi=400)
plt.show()
```
Now I will do a ranking of my most listened albums. For this I need to aggregate Play Counts at album level. I will also discard singles or albums with too few songs
```{python}
# Filter albums that I consider as "full": those with more than 5 songs
ntracks_album=df_tracks.groupby('Album').size()
full_albums=(ntracks_album[ntracks_album>5]
             .reset_index()
             .rename(columns={0: "n_tracks"}))
full_albums
```

Now let's aggregate play count at album level, and then filter by the previous dataframe
```{python}
plays_by_album= (df_tracks
.groupby('Album')['Play Count']
.sum()
.reset_index()
.sort_values(by='Play Count', ascending=False))

full_albums_ranked=plays_by_album[plays_by_album.Album.isin(full_albums.Album)]
full_albums_ranked.head(10)
```

OK, but I think plot will be less cluttered if I remove the text between parentheses in some albums names (i.e. "Deluxe Version" and "Original Motion Picture..."). This can be done through the string manipulation functions in Python:
```{python remove-text-parentheses}
full_albums_ranked['Album']=(full_albums_ranked
                          .Album.str.replace(' \(.+\)$', '', regex=True))
```




Now let's create the plot with the top albums:
```{python plot-top-albums}
plt.clf()
ax=sns.barplot(x='Play Count',
               y='Album',
               hue='Play Count',
              data=full_albums_ranked.head(10),
              dodge=False,
              palette='OrRd')
              
# Rotating labels trying to make them fit
ax.figure.set_size_inches(7,5)
ax.xaxis.grid(True)  
plt.tight_layout()
plt.legend([],[], frameon=False)
plt.savefig('test2.png', dpi=400)
plt.show()
```

So, doing the ranking of songs was straightforward, and so was the ranking of albums, despite involving a couple of extra steps. But now I will try to do something a bit more complex. In order to obtain a ranking of artists by play count, I want to parse the artist attribute for collaborations (songs by more than one artists) so the play counts of these songs count for each one of those artists.

For example, one of my most played songs is "Top Gone" by Lil Mosey and Lunay. If didn't parsed the artist for that song, when doing the ranking those play counts wouldn't count for Lil Mosey nor Lunay, but for a third, totally different artist named 'Lil Mosey & Lunay". Obviously I don't want that.

The first thing here is look at all the strings that signal a collaboration. In my collection these are:

* ' & '
* ', ' 
* ' Feat. '
* ' feat. '
* '/'	

I may also want to look for exceptions: cases where those strings are present, but there is no collaboration. There are three such cases in my collection:

* Zion & Lenox
* Wisin & Yandel
* Now, Now

The first two are duets of reggaeton singers, 

so it would make sense to keep them together.
[explain that the name of the duet is just the name of the individual artists combined ]
However, both of them have released solo songs, so it also makes sense to split to treat them as different artists collaborating. I will do the latter.

The third case is an indie rock duo from Minnesota. Here the name of the band is not a combination of the name of the members, but instead an indivisible "artistic name", so I will add this as an exception.

After splitting the artist string, I want to create a data structure that allows a 1:N relationship between songs and artists (so the plays count of each song add to each of the contribuiting artists).

I think the appropiate data structure for this is a list of dictionaries, where each dictionary represents a song, and where one of the values of each dictionary is a lists of artists. 

```{python split-artists-strings}
delimiters=' & ',', ',' Feat. ',' feat. ','/'
regexPattern = '|'.join(map(re.escape, delimiters))
reg_split=re.compile(regexPattern)
artists_splitted=df_tracks.Artist.str.split(regexPattern)
artists_splitted[:10]
```


```{python}
songs=[]
for i, song in df_tracks.Name.items():
  ## Parse the artists of the song
  if df_tracks.Artist.values[i]=='Now, Now':
    artist_to_assign=[df_tracks.Artist.values[i]]
  else:
    artist_to_assign=artists_splitted.values[i]
  
  ## add elements to the list of songs
  songs.append({'Name': song,
                'Number': i,
                'Artists': artist_to_assign})

```

Trying to catch artists who appear in the song name as 'feat.'
```{python}
contains_feat=df_tracks.Name.str.contains('\(feat.')
View(df_tracks[['Name']][contains_feat])

```

There are three patterns for featuring artists in song names:

* Song name (feat. Artists names) (or sometimes just '(feat Artists names)', without the dot)
* Song name [feat. Artists names]
* Song name feat. Artist name

I could try to create a unique general regex that extracts artist(s) name(s) in all these cases, but a better option is to just create a simpler regex for each one, and then apply them based on conditional logic and `str.contains`.

```{python}
re_circ_brackets=re.compile(' \(feat\.* (.*)\)')
re_sq_brackets=re.compile(' \[feat. ([^\[]*)\]')
re_bare=re.compile(' feat. (.*)$')
```


```{python}
# Idea: create three boolean arrays, and then use them to implement a for loop with conditional logic
feat_curved_brackets=df_tracks.Name.str.contains('\(feat.').values
feat_squared_brackets=df_tracks.Name.str.contains('\[feat.').values
feat_bare=df_tracks.Name.str.contains(' feat.').values

for i, song in df_tracks.Name.items():
  # reg_compiled.split(match)
  if feat_curved_brackets[i]:
    artists_feat=re_circ_brackets.search(song)[1]
  elif feat_squared_brackets[i]:
    artists_feat=re_sq_brackets.search(song)[1]
  elif feat_bare[i]:
    artists_feat=re_bare.search(song)[1]
    
  if (feat_curved_brackets[i] or feat_squared_brackets[i] or feat_bare[i]):
    splitted_artists_feat=reg_split.split(artists_feat)
    songs[i]['Artists'].extend(splitted_artists_feat)

```

Now I will apply some transformations to artists names in order to normalize them and avoid their play counts getiing splitted due to different spelling (e.g. ROSALÍA vs Rosalía, and J. Balvin vs J Balvin).
```{python}
for i in range(len(songs)):
  for j in range(len(songs[i]['Artists'])):
    artist_name=songs[i]['Artists'][j]
    norm_artist_name=artist_name.title().replace('.', '')
    songs[i]['Artists'][j]=norm_artist_name
    

```

Then, finally, I can add up the play counts by artist:
```{python}
artists={}

for i in range(len(songs)):
  for j in range(len(songs[i]['Artists'])):
    if songs[i]['Artists'][j] not in artists:
      artists[songs[i]['Artists'][j]]=df_tracks['Play Count'][i]
    else:
      artists[songs[i]['Artists'][j]]+=df_tracks['Play Count'][i]
    

```

And now, finally, I can get my ranking!
```{python}
df_artists_plays=pd.DataFrame(artists.items(),
                              columns=['Artist', 'Play Count']) 
                              
df_artists_plays
```
Getting the top 10 for the plot
```{python}
df_artists_plot=(df_artists_plays
                 .sort_values(by='Play Count', ascending=False)
                 .head(10))
  
df_artists_plot
```

And now the plot itself:
```{python plot-top-artists}
plt.clf()
ax=sns.barplot(x='Play Count',
               y='Artist',
               hue='Play Count',
              data=df_artists_plot,
              dodge=False,
              palette='OrRd')
              
# Rotating labels trying to make them fit
ax.figure.set_size_inches(7,5)
ax.xaxis.grid(True)  
plt.tight_layout()
plt.legend([],[], frameon=False)
plt.show()
```

## Songs by decades and five-year periods

Finally, it would be interesting (for me) to know how my music listening relates to the year in which songs were released. From the ranking above you can already guess that I lean heavily into more modern/contemporary music, and not so much into songs from the 90's or previous decades. But there still could be some interesting variation between more recent periods (let's say, 2010-2014 vs 2015-2019 vs 2020-2022).

First, I will create a five-year period column in the original tracks dataframe:
```{python}
df_tracks[['Year']]=df_tracks[['Year']].apply(pd.to_numeric)
```


```{python}
df_tracks=(df_tracks
.assign(FiveYearPeriod=pd.to_numeric(np.floor(df_tracks.Year / 5) * 5, downcast='integer')))

df_tracks.groupby('FiveYearPeriod').size()
```

Two changes that I would do here: 
- Since there are so few songs from before 1995, I want to group all of them in a category labeled as 'Before 1995'.
```{python}
df_tracks.FiveYearPeriod=['Before 1995' if year < 1995 else year for year in df_tracks.FiveYearPeriod]
```

- Convert the FiveYearPeriod into categorical, and give each period a nice label (such as '2015-2019').
```{python}
catg_years=pd.Categorical(df_tracks.FiveYearPeriod,
               ordered=True,
               categories=['Before 1995', 1995, 2000, 2005, 2010, 2015, 2020])
```


```{python}
catg_years.rename_categories({1995: '1995-1999', 2000: '2000-2004', 2005: '2005-2009', 2010: '2010-2014', 2015: '2015-2019', 2020: '2020-Present'})


```
```{python}
df_tracks.FiveYearPeriod=catg_years
```

Now get summary statistics per period:
- Total songs
- Total play counts
- 3 songs with more plays
- Share of liked songs per period

Then finally, create pretty ggplots using reticulate magic, but also a seaborn plot with points (maybe distribution of songs per Play Count?)
